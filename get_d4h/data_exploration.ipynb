{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbc4bdf8",
   "metadata": {},
   "source": [
    "# D4H Incident Data Exploration\n",
    "\n",
    "This notebook explores Search and Rescue incident data from D4H (Disaster4Help), loaded from `incidents.json`.\n",
    "\n",
    "## Overview\n",
    "- Load and clean incident data using our custom data utilities\n",
    "- Perform exploratory data analysis\n",
    "- Visualize key patterns and insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f507f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "from datetime import datetime\n",
    "\n",
    "# Import our custom data utilities\n",
    "import data_utils\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e646dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process the incidents data using our helper functions\n",
    "print(\"Loading incidents data...\")\n",
    "df = data_utils.load_and_process_incidents('incidents.json')\n",
    "\n",
    "print(f\"Successfully loaded {len(df)} incidents\")\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(f\"Date range: {df['startsAt'].min()} to {df['startsAt'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570238fe",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "Let's explore the structure and content of our incident data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb766d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics for numerical columns\n",
    "print(\"=== NUMERICAL STATISTICS ===\")\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "display(df[numerical_cols].describe())\n",
    "\n",
    "print(\"\\n=== INCIDENT SUMMARY ===\")\n",
    "summary = data_utils.get_incident_summary(df)\n",
    "for key, value in summary.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"\\n=== CATEGORICAL INSIGHTS ===\")\n",
    "if 'address.town' in df.columns:\n",
    "    print(f\"Top 5 towns by incident count:\")\n",
    "    print(df['address.town'].value_counts().head())\n",
    "\n",
    "if 'night' in df.columns:\n",
    "    print(f\"\\nDay vs Night incidents:\")\n",
    "    print(df['night'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d80fe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data overview and structure\n",
    "print(\"=== DATASET OVERVIEW ===\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "print(\"\\n=== COLUMN INFORMATION ===\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\n=== MISSING VALUES ===\")\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df) * 100).round(1)\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing,\n",
    "    'Missing %': missing_pct\n",
    "}).sort_values('Missing Count', ascending=False)\n",
    "print(missing_df[missing_df['Missing Count'] > 0].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8e301a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the cleaned data\n",
    "print(\"First 5 incidents:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nColumn names and types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba5ae72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify data cleaning results\n",
    "print(\"=== DATA CLEANING VERIFICATION ===\")\n",
    "\n",
    "# Check if coordinates were properly parsed\n",
    "if 'latitude' in df.columns and 'longitude' in df.columns:\n",
    "    print(\"✓ Coordinates successfully parsed\")\n",
    "    print(f\"  Latitude range: {df['latitude'].min():.4f} to {df['latitude'].max():.4f}\")\n",
    "    print(f\"  Longitude range: {df['longitude'].min():.4f} to {df['longitude'].max():.4f}\")\n",
    "else:\n",
    "    print(\"✗ Coordinates not found\")\n",
    "\n",
    "# Check date parsing\n",
    "date_cols = ['createdAt', 'startsAt', 'endsAt']\n",
    "for col in date_cols:\n",
    "    if col in df.columns:\n",
    "        print(f\"✓ {col}: {df[col].dtype}\")\n",
    "    else:\n",
    "        print(f\"✗ {col}: not found\")\n",
    "\n",
    "# Check for HTML in descriptions\n",
    "if 'description' in df.columns:\n",
    "    html_count = df['description'].str.contains('<.*>', regex=True, na=False).sum()\n",
    "    print(f\"HTML tags in descriptions: {html_count} (should be 0 after cleaning)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1c246d",
   "metadata": {},
   "source": [
    "## Temporal Analysis\n",
    "\n",
    "Let's analyze incident patterns over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4ea76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Incident Temporal Patterns', fontsize=16)\n",
    "\n",
    "# Incidents by year\n",
    "if 'startsAt' in df.columns:\n",
    "    df['year'] = df['startsAt'].dt.year\n",
    "    yearly_counts = df['year'].value_counts().sort_index()\n",
    "    \n",
    "    axes[0,0].bar(yearly_counts.index, yearly_counts.values)\n",
    "    axes[0,0].set_title('Incidents by Year')\n",
    "    axes[0,0].set_xlabel('Year')\n",
    "    axes[0,0].set_ylabel('Number of Incidents')\n",
    "    axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Incidents by month\n",
    "if 'startsAt' in df.columns:\n",
    "    df['month'] = df['startsAt'].dt.month\n",
    "    monthly_counts = df['month'].value_counts().sort_index()\n",
    "    \n",
    "    axes[0,1].bar(monthly_counts.index, monthly_counts.values)\n",
    "    axes[0,1].set_title('Incidents by Month')\n",
    "    axes[0,1].set_xlabel('Month')\n",
    "    axes[0,1].set_ylabel('Number of Incidents')\n",
    "\n",
    "# Incidents by day of week\n",
    "if 'startsAt' in df.columns:\n",
    "    df['day_of_week'] = df['startsAt'].dt.day_name()\n",
    "    day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    day_counts = df['day_of_week'].value_counts().reindex(day_order)\n",
    "    \n",
    "    axes[1,0].bar(range(len(day_counts)), day_counts.values)\n",
    "    axes[1,0].set_title('Incidents by Day of Week')\n",
    "    axes[1,0].set_xlabel('Day of Week')\n",
    "    axes[1,0].set_ylabel('Number of Incidents')\n",
    "    axes[1,0].set_xticks(range(len(day_counts)))\n",
    "    axes[1,0].set_xticklabels(day_counts.index, rotation=45)\n",
    "\n",
    "# Incidents by hour\n",
    "if 'startsAt' in df.columns:\n",
    "    df['hour'] = df['startsAt'].dt.hour\n",
    "    hourly_counts = df['hour'].value_counts().sort_index()\n",
    "    \n",
    "    axes[1,1].bar(hourly_counts.index, hourly_counts.values)\n",
    "    axes[1,1].set_title('Incidents by Hour of Day')\n",
    "    axes[1,1].set_xlabel('Hour')\n",
    "    axes[1,1].set_ylabel('Number of Incidents')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d466d7",
   "metadata": {},
   "source": [
    "## Geographical Analysis\n",
    "\n",
    "Explore the spatial distribution of incidents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcb93df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geographical analysis\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "fig.suptitle('Geographical Distribution of Incidents', fontsize=16)\n",
    "\n",
    "# Top locations by incident count\n",
    "if 'address.town' in df.columns:\n",
    "    top_towns = df['address.town'].value_counts().head(10)\n",
    "    axes[0].barh(range(len(top_towns)), top_towns.values)\n",
    "    axes[0].set_yticks(range(len(top_towns)))\n",
    "    axes[0].set_yticklabels(top_towns.index)\n",
    "    axes[0].set_title('Top 10 Towns by Incident Count')\n",
    "    axes[0].set_xlabel('Number of Incidents')\n",
    "\n",
    "# Distance distribution\n",
    "if 'distance' in df.columns:\n",
    "    # Remove outliers for better visualization\n",
    "    q99 = df['distance'].quantile(0.99)\n",
    "    distance_filtered = df[df['distance'] <= q99]['distance']\n",
    "    \n",
    "    axes[1].hist(distance_filtered, bins=50, alpha=0.7, edgecolor='black')\n",
    "    axes[1].set_title('Distribution of Incident Distances')\n",
    "    axes[1].set_xlabel('Distance (meters)')\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "\n",
    "# Scatter plot of coordinates (if available)\n",
    "if 'latitude' in df.columns and 'longitude' in df.columns:\n",
    "    valid_coords = df.dropna(subset=['latitude', 'longitude'])\n",
    "    axes[2].scatter(valid_coords['longitude'], valid_coords['latitude'], \n",
    "                   alpha=0.6, s=20)\n",
    "    axes[2].set_title('Incident Locations')\n",
    "    axes[2].set_xlabel('Longitude')\n",
    "    axes[2].set_ylabel('Latitude')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print geographical summary\n",
    "print(\"=== GEOGRAPHICAL SUMMARY ===\")\n",
    "if 'address.town' in df.columns:\n",
    "    print(f\"Number of unique towns: {df['address.town'].nunique()}\")\n",
    "    # Filter out rows with missing or empty town values\n",
    "    towns_with_name = df[df['address.town'].notna() & (df['address.town'].str.strip() != \"\")]\n",
    "    if not towns_with_name.empty:\n",
    "        print(f\"Most incidents in: {towns_with_name['address.town'].mode().iloc[0]}\")\n",
    "    else:\n",
    "        print(\"No valid town data available.\")\n",
    "\n",
    "if 'distance' in df.columns:\n",
    "    print(f\"Average distance: {df['distance'].mean():.0f} meters\")\n",
    "    print(f\"Max distance: {df['distance'].max():.0f} meters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ca27e7",
   "metadata": {},
   "source": [
    "## Interactive Heatmap\n",
    "\n",
    "Let's create an interactive heatmap of incident locations using Folium to visualize the geographic density of Search and Rescue incidents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0189cf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive heatmap using Folium\n",
    "if 'latitude' in df.columns and 'longitude' in df.columns:\n",
    "    # Filter out rows with valid coordinates\n",
    "    valid_coords_df = df.dropna(subset=['latitude', 'longitude']).copy()\n",
    "    \n",
    "    print(f\"Creating maps with {len(valid_coords_df)} incidents that have coordinates\")\n",
    "    \n",
    "    if len(valid_coords_df) > 0:\n",
    "        # Taylor's Landing coordinates (home base)\n",
    "        taylors_landing_lat = 47.94964\n",
    "        taylors_landing_lon = -122.077301\n",
    "        \n",
    "        print(f\"Map centered on Taylor's Landing: {taylors_landing_lat}, {taylors_landing_lon}\")\n",
    "        \n",
    "        # === HEATMAP ===\n",
    "        # Create base map centered on Taylor's Landing\n",
    "        heatmap = folium.Map(\n",
    "            location=[taylors_landing_lat, taylors_landing_lon],\n",
    "            zoom_start=9,\n",
    "            tiles='OpenStreetMap'\n",
    "        )\n",
    "        \n",
    "        # Add Taylor's Landing marker\n",
    "        folium.Marker(\n",
    "            location=[taylors_landing_lat, taylors_landing_lon],\n",
    "            popup=folium.Popup(\"<b>Taylor's Landing</b><br>SAR Home Base\", max_width=200),\n",
    "            icon=folium.Icon(color='green', icon='home', prefix='fa')\n",
    "        ).add_to(heatmap)\n",
    "        \n",
    "        # Prepare data for heatmap - list of [lat, lon] pairs\n",
    "        heat_data = [[row['latitude'], row['longitude']] for _, row in valid_coords_df.iterrows()]\n",
    "        \n",
    "        # Add heatmap layer\n",
    "        HeatMap(\n",
    "            heat_data,\n",
    "            min_opacity=0.3,\n",
    "            max_zoom=18,\n",
    "            radius=17,\n",
    "            blur=15,\n",
    "            gradient={\n",
    "            0.1: 'blue',\n",
    "            0.3: 'lime',\n",
    "            0.5: 'yellow',\n",
    "            0.7: 'orange',\n",
    "            0.8: 'red'\n",
    "            }\n",
    "        ).add_to(heatmap)\n",
    "        \n",
    "        # Add layer control\n",
    "        folium.LayerControl().add_to(heatmap)\n",
    "        \n",
    "        print(\"📍 Incident Density Heatmap:\")\n",
    "        display(heatmap)\n",
    "        \n",
    "        # === INCIDENT POINTS MAP ===\n",
    "        # Create second map for individual incident markers\n",
    "        incidents_map = folium.Map(\n",
    "            location=[taylors_landing_lat, taylors_landing_lon],\n",
    "            zoom_start=9,\n",
    "            tiles='CartoDB positron'\n",
    "        )\n",
    "        \n",
    "        # Add Taylor's Landing marker\n",
    "        folium.Marker(\n",
    "            location=[taylors_landing_lat, taylors_landing_lon],\n",
    "            popup=folium.Popup(\"<b>Taylor's Landing</b><br>SAR Home Base\", max_width=200),\n",
    "            icon=folium.Icon(color='green', icon='home', prefix='fa')\n",
    "        ).add_to(incidents_map)\n",
    "        \n",
    "        # Add all incident markers\n",
    "        for _, incident in valid_coords_df.iterrows():\n",
    "            # Create popup text with incident details\n",
    "            popup_text = f\"\"\"\n",
    "            <b>Incident:</b> {incident.get('referenceDescription', 'N/A')}<br>\n",
    "            <b>Date:</b> {str(incident.get('startsAt', 'N/A'))[:10]}<br>\n",
    "            <b>Town:</b> {incident.get('address.town', 'N/A')}<br>\n",
    "            <b>Attendance:</b> {incident.get('countAttendance', 'N/A')} people<br>\n",
    "            <b>Night:</b> {'Yes' if incident.get('night', False) else 'No'}<br>\n",
    "            <b>Distance:</b> {incident.get('distance', 'N/A')} meters\n",
    "            \"\"\"\n",
    "            \n",
    "            # Color code by night/day\n",
    "            color = 'darkblue' if incident.get('night', False) else 'orange'\n",
    "            fillColor = 'blue' if incident.get('night', False) else 'yellow'\n",
    "            \n",
    "            folium.CircleMarker(\n",
    "                location=[incident['latitude'], incident['longitude']],\n",
    "                radius=4,\n",
    "                popup=folium.Popup(popup_text, max_width=300),\n",
    "                color=color,\n",
    "                fillColor=fillColor,\n",
    "                fillOpacity=0.7,\n",
    "                weight=2\n",
    "            ).add_to(incidents_map)\n",
    "        \n",
    "        # Add layer control\n",
    "        folium.LayerControl().add_to(incidents_map)\n",
    "        \n",
    "        print(f\"\\n🗺️ Individual Incident Locations ({len(valid_coords_df)} incidents):\")\n",
    "        print(\"Blue markers = Night incidents, Yellow markers = Day incidents\")\n",
    "        display(incidents_map)\n",
    "        \n",
    "    else:\n",
    "        print(\"No valid coordinates found for maps\")\n",
    "else:\n",
    "    print(\"Latitude and longitude columns not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09792f8a",
   "metadata": {},
   "source": [
    "## Summary and Key Insights\n",
    "\n",
    "Based on our analysis of the D4H incident data, here are the key findings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a1c3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary insights\n",
    "print(\"🔍 KEY INSIGHTS FROM D4H INCIDENT DATA ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Data overview\n",
    "print(f\"📊 DATASET OVERVIEW:\")\n",
    "print(f\"   • Total incidents analyzed: {len(df):,}\")\n",
    "print(f\"   • Date range: {df['startsAt'].min().strftime('%Y-%m-%d')} to {df['startsAt'].max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"   • Geographic coverage: {df['address.town'].nunique()} towns across {df['address.region'].nunique()} regions\")\n",
    "\n",
    "# Temporal patterns\n",
    "print(f\"\\n⏰ TEMPORAL PATTERNS:\")\n",
    "if 'night' in df.columns:\n",
    "    night_pct = (df['night'].sum() / len(df) * 100)\n",
    "    print(f\"   • {night_pct:.1f}% of incidents occur at night\")\n",
    "\n",
    "if 'year' in df.columns:\n",
    "    peak_year = df['year'].mode().iloc[0]\n",
    "    peak_count = df['year'].value_counts().iloc[0]\n",
    "    print(f\"   • Peak incident year: {peak_year} ({peak_count} incidents)\")\n",
    "\n",
    "if 'month' in df.columns:\n",
    "    peak_month = df['month'].mode().iloc[0]\n",
    "    month_names = ['', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "                   'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "    print(f\"   • Most active month: {month_names[peak_month]}\")\n",
    "\n",
    "# Geographic patterns\n",
    "print(f\"\\n🗺️ GEOGRAPHIC PATTERNS:\")\n",
    "if 'address.town' in df.columns:\n",
    "    # Filter out empty/missing town names\n",
    "    towns_with_data = df[df['address.town'].notna() & (df['address.town'].str.strip() != \"\")]\n",
    "    if not towns_with_data.empty:\n",
    "        top_town = towns_with_data['address.town'].mode().iloc[0]\n",
    "        top_count = towns_with_data['address.town'].value_counts().iloc[0]\n",
    "        print(f\"   • Highest incident town: {top_town} ({top_count} incidents)\")\n",
    "\n",
    "if 'distance' in df.columns:\n",
    "    avg_distance = df['distance'].mean()\n",
    "    max_distance = df['distance'].max()\n",
    "    print(f\"   • Average incident distance: {avg_distance:.0f} meters\")\n",
    "    print(f\"   • Maximum incident distance: {max_distance:.0f} meters\")\n",
    "\n",
    "# Team response patterns\n",
    "print(f\"\\n👥 TEAM RESPONSE PATTERNS:\")\n",
    "if 'countAttendance' in df.columns:\n",
    "    avg_attendance = df['countAttendance'].mean()\n",
    "    max_attendance = df['countAttendance'].max()\n",
    "    print(f\"   • Average team size: {avg_attendance:.1f} people\")\n",
    "    print(f\"   • Largest response: {max_attendance} people\")\n",
    "\n",
    "if 'percAttendance' in df.columns:\n",
    "    avg_attendance_pct = df['percAttendance'].mean()\n",
    "    print(f\"   • Average attendance rate: {avg_attendance_pct:.1f}%\")\n",
    "\n",
    "# Data quality\n",
    "print(f\"\\n✅ DATA QUALITY:\")\n",
    "coord_coverage = len(df.dropna(subset=['latitude', 'longitude'])) / len(df) * 100\n",
    "print(f\"   • Geographic coordinate coverage: {coord_coverage:.1f}%\")\n",
    "\n",
    "missing_descriptions = df['description'].isna().sum()\n",
    "print(f\"   • Incidents with descriptions: {len(df) - missing_descriptions:,} ({(len(df) - missing_descriptions)/len(df)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n💡 The interactive heatmap above shows the geographic distribution of incidents,\")\n",
    "print(f\"   with red areas indicating higher concentrations of Search and Rescue activity.\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "get-d4h",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
